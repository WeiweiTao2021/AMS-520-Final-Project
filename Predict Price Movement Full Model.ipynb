{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMS 520 Final Project\n",
    "\n",
    "This notebook contains codes and report implementing 'Model high-frequency limit order book dynamics with SVM' written by Edward Cummings, Anton Malandii, Jack Peters, and Weiwei Tao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq pyarrow\n",
    "!pip install -qq xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as fn\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Data Exploration\n",
    "\n",
    "### Trade dataset\n",
    "\n",
    "The trade dataset contains 243K UTP trade records from 14 different Stock Exchanges on 2022-01-06 between 4 a.m. until 8 p.m. EST for AAPL.\n",
    "\n",
    "\n",
    "### Quote dataset\n",
    "The quote dataset contains 473K UTP quote records from 13 different Stock Exchanges on 2022-01-06 for AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9g/k3f7lx5n4cnb1yd775c6k7bw0000gn/T/ipykernel_34631/2188346647.py:2: DtypeWarning:\n",
      "\n",
      "Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = pd.read_csv('query_trades_AAPL_20200106_born202210121745.csv',)\n",
    "q = pd.read_csv('query_quotes_AAPL_20200106_born202210121744.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242878, 17), (473340, 31))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape, q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Data Cleaning\n",
    "\n",
    "We first removed the closing/opening auction dissemination ( remove first and last 15 min) and excluded trades from the exchange D from our analysis. Then, trades and quote updates that stem from the same marketable order execution were regrouped together. We used the participant timestamp to assign a unique marketable order execution (MOX) identifier to each batch of trades and quotes triggered in execution of a single marketable order. Note that the reason that the participant timestamp can be used to derive the MOX identifier because all trades and quote updates that are triggered in the execution of the same marketable order receive the same participant (but not SIP) timestamp in high resolution.\n",
    "\n",
    "After data cleaning, the analysis dataset contains 395K records. For each records, following features are generated:\n",
    "1. Time\n",
    "2. ask/bid price/volume, mid price, spread\n",
    "3. dPask_dt, dPbid_dt, dVask_dt, dVbid_dt\n",
    "4. average trade price/volume within 10ms, 100ms, 1s and 10s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taq_data_cleaning import gen_basic_features_TAQ, gen_targets_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiweitao/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6999: FutureWarning:\n",
      "\n",
      "In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395698, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'time', 'ask_price', 'bid_price', 'ask_volume', 'bid_volume',\n",
       "       'mid_price', 'spread', 'dPask_dt', 'dPbid_dt', 'dVask_dt', 'dVbid_dt',\n",
       "       'avg_trade_price_10ms', 'avg_trade_price_100ms', 'avg_trade_price_1s',\n",
       "       'avg_trade_price_10s', 'avg_trade_volume_10ms',\n",
       "       'avg_trade_volume_100ms', 'avg_trade_volume_1s',\n",
       "       'avg_trade_volume_10s'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = gen_basic_features_TAQ(t, q,)\n",
    "\n",
    "print(df_features.shape)\n",
    "df_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Generate Labels\n",
    "\n",
    "Both event-base and time-based outcomes were evaluated. \n",
    "1. After 30 orders, whether the price and spread will go down, unchanged or up.\n",
    "2. After 100 ms, whether the price and spread will go down, unchanged or up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>midup</th>\n",
       "      <th>middown</th>\n",
       "      <th>mideq</th>\n",
       "      <th>spreadup</th>\n",
       "      <th>spreaddown</th>\n",
       "      <th>spreadeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42179</td>\n",
       "      <td>2214126</td>\n",
       "      <td>35100.044580</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42181</td>\n",
       "      <td>2214141</td>\n",
       "      <td>35100.044763</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42182</td>\n",
       "      <td>2214146</td>\n",
       "      <td>35100.044834</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42183</td>\n",
       "      <td>2214167</td>\n",
       "      <td>35100.045857</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42184</td>\n",
       "      <td>2214865</td>\n",
       "      <td>35100.094862</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       id          time  midup  middown  mideq  spreadup  spreaddown  \\\n",
       "0  42179  2214126  35100.044580  False     True  False     False       False   \n",
       "1  42181  2214141  35100.044763  False     True  False     False       False   \n",
       "2  42182  2214146  35100.044834  False     True  False     False       False   \n",
       "3  42183  2214167  35100.045857  False     True  False     False       False   \n",
       "4  42184  2214865  35100.094862  False     True  False     False       False   \n",
       "\n",
       "   spreadeq  \n",
       "0      True  \n",
       "1      True  \n",
       "2      True  \n",
       "3      True  \n",
       "4      True  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events = gen_targets_events(q,num_events=30)\n",
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    369298\n",
       "True      26370\n",
       "Name: spreadup, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events['spreadup'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    363617\n",
       "True      32051\n",
       "Name: spreaddown, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events['spreaddown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     363617\n",
       "False     32051\n",
       "Name: spreadeq, dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events['spreadeq'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Equal    363617\n",
       "Down      32051\n",
       "Name: yspread, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.loc[df_events['spreadup'] == True, 'yspread'] = 'Up'\n",
    "df_events.loc[df_events['spreadeq'] == True, 'yspread'] = 'Equal'\n",
    "df_events.loc[df_events['spreaddown'] == True, 'yspread'] = 'Down'\n",
    "df_events['yspread'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_time = gen_targets_temporal(q,prediction_interval=100)\n",
    "df_targets_time.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_combined(df_features, df_targets_time, df_events=None ):\n",
    "\n",
    "    #Explicit merge, should use left join instead\n",
    "    try:\n",
    "        df_features.set_index('id', inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df_features.sort_index(inplace=True)\n",
    "    try:\n",
    "        df_targets_time.set_index('id', inplace=True) \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df_targets_time.sort_index(inplace=True)\n",
    "    ntarg = []\n",
    "    for col in df_targets_time.columns:\n",
    "        if 'mid' in col or 'spread' in col:\n",
    "            ntarg += [col]\n",
    "            \n",
    "    ind_comb = set(df_features.index.to_numpy()).intersection(set(df_targets_time.index.to_numpy()))\n",
    "    df_combine = df_features.loc[ind_comb]\n",
    "    df_combine[ntarg] = df_targets_time[ntarg].loc[ind_comb]\n",
    "    \n",
    "    if ~isinstance(df_events, type(None)):\n",
    "        try:\n",
    "            df_events.set_index('id', inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        nevent = []\n",
    "        for col in df_events.columns:\n",
    "            if 'mid' in col or 'spread' in col:\n",
    "                nevent += [col]\n",
    "        ind_comb = ind_comb.intersection(set(df_events.index.to_numpy()))\n",
    "   \n",
    "        df_combine[nevent] = df_events[nevent].loc[ind_comb]\n",
    "    return df_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine =  create_df_combined(df_features, df_targets_time, df_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine.reset_index(inplace=True)\n",
    "df_combine.to_feather(\"clean_combine_30e_50ms_AAPL_20200106.f\") ## checkpoint combined features/targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "cols = []\n",
    "for col in df_combine.columns:\n",
    "    if 'mid' in col or 'spread' in col:\n",
    "        cols += [col]\n",
    "cols = cols[2:]\n",
    "fig = go.Figure(layout=go.Layout(height=400, width=800))\n",
    "fig.add_bar(x=cols,y=df_combine[cols].sum()/len(df_combine))\n",
    "fig.update_layout(title_text=\"Distribution of Outcomes\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine.rename(columns = {'avg_trade_price_10ms':'AvgP_10ms', \n",
    "                             'avg_trade_price_100ms':'AvgP_100ms', \n",
    "                             'avg_trade_price_1s':'AvgP_1s', \n",
    "                             'avg_trade_price_10s':'AvgP_10s', \n",
    "                             'avg_trade_volume_10ms':'AvgV_10ms', \n",
    "                             'avg_trade_volume_100ms':'AvgV_100ms', \n",
    "                             'avg_trade_volume_1s':'AvgV_1s', \n",
    "                             'avg_trade_volume_10s':'AvgV_10s', \n",
    "                            }, inplace = True)\n",
    "\n",
    "focus_columns = ['ask_price', 'bid_price', 'ask_volume', 'bid_volume', \n",
    "                 'mid_price', 'spread', 'dPask_dt', 'dPbid_dt', 'dVask_dt', 'dVbid_dt', \n",
    "                 'AvgP_10ms', 'AvgP_100ms', 'AvgP_1s', 'AvgP_10s', \n",
    "                 'AvgV_10ms', 'AvgV_100ms', 'AvgV_1s', 'AvgV_10s']\n",
    "\n",
    "corr=df_combine[focus_columns].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "heat_fig, (ax)=plt.subplots(1, 1, figsize=(8,5))\n",
    "\n",
    "heat=sns.heatmap(corr, \n",
    "                   ax=ax,  \n",
    "                   mask=mask, vmin=-1, vmax=1, annot=False, cmap='BrBG')\n",
    "\n",
    "heat_fig.subplots_adjust(top=.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['hour'] = df_features['time']/3600\n",
    "df_features.set_index('hour', inplace = True)\n",
    "cols = ['ask_price', 'bid_price', 'ask_volume', 'bid_volume', 'mid_price', 'spread']\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "df_features[cols].plot(subplots=True, figsize=(12, 9),fontsize=10, sharex=False, layout=(3, 2),  linewidth=2, title='Visualization of the original Time Series');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Train-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine.loc[df_combine['midup'] == True, 'ymid'] = 'Up'\n",
    "df_combine.loc[df_combine['mideq'] == True, 'ymid'] = 'Equal'\n",
    "df_combine.loc[df_combine['middown'] == True, 'ymid'] = 'Down'\n",
    "df_combine['ymid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine.loc[df_combine['spreadup'] == True, 'yspread'] = 'Up'\n",
    "df_combine.loc[df_combine['spreadeq'] == True, 'yspread'] = 'Equal'\n",
    "df_combine.loc[df_combine['spreaddown'] == True, 'yspread'] = 'Down'\n",
    "df_combine['yspread'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df_combine['y'] = encoder.fit_transform(df_combine['ymid'])\n",
    "X_train, X_test, y_train, y_test=train_test_split(df_combine[focus_columns], df_combine['y'], test_size=0.1 ,shuffle=False, stratify=None)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Build Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "078ac81e2b2852bb637df30caaf44341a661a1dcf7f43814fa7a1961f9b91a88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
